{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     # Currently, memory growth needs to be the same across GPUs\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Memory growth must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "df = pd.read_csv('./data/continuous dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************** Data Pre-Processing ****************************************\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "class TabularLSTMDataPreprocessor:\n",
    "    def __init__(self, dataframe, target_column, time_column, categorical_columns=None,\n",
    "                 scaler='minmax', sequence_length=24, batch_size=32, random_state=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.target_column = target_column\n",
    "        self.time_column = time_column\n",
    "        self.categorical_columns = categorical_columns if categorical_columns else []\n",
    "        self.scaler = self.get_scaler(scaler)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.batch_size = batch_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_scaler(self, scaler_type):\n",
    "        if scaler_type == 'minmax':\n",
    "            return MinMaxScaler()\n",
    "        elif scaler_type == 'standard':\n",
    "            return StandardScaler()\n",
    "        else:\n",
    "            raise ValueError(\"Invalid scaler type. Use 'minmax' or 'standard'.\")\n",
    "\n",
    "    def preprocess(self):\n",
    "        #Creating lag features\n",
    "        windows = [12, 24, 128]\n",
    "        for column in self.dataframe.columns:\n",
    "            if column != self.time_column and column not in self.categorical_columns:\n",
    "                for window in windows:\n",
    "                    self.dataframe[f\"{column}_lag_{window}\"] = self.dataframe[column].shift(window)\n",
    "                    # Add other transformations as needed\n",
    "\n",
    "        # Drop rows with missing values\n",
    "        self.dataframe.dropna(inplace=True)\n",
    "\n",
    "        # Sort by time\n",
    "        self.dataframe.sort_values(by=[self.time_column], inplace=True)\n",
    "        \n",
    "        # Scale numerical features\n",
    "        numerical_columns = [col for col in self.dataframe.columns if col not in [self.target_column, self.time_column, self.categorical_columns]]\n",
    "        self.dataframe[numerical_columns] = self.scaler.fit_transform(self.dataframe[numerical_columns])\n",
    "\n",
    "        # Apply one-hot encoding to categorical columns (if any)\n",
    "        if self.categorical_columns:\n",
    "            self.dataframe = pd.get_dummies(self.dataframe, columns=self.categorical_columns, drop_first=True)\n",
    "        \n",
    "        train_df = self.dataframe[self.dataframe[self.time_column] < '2019-01-01']\n",
    "        test_df = self.dataframe[self.dataframe[self.time_column] >= '2019-01-01']\n",
    "        # Split data into train and test sets\n",
    "        X_train = train_df.drop(columns=[self.target_column, self.time_column]).values.astype(np.float32)\n",
    "        y_train = train_df[self.target_column].values.astype(np.float32)\n",
    "#         X = X.astype(np.float32)\n",
    "#         y = y.astype(np.float32)\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state, shuffle=False)\n",
    "        X_test = test_df.drop(columns=[self.target_column, self.time_column]).values.astype(np.float32)\n",
    "        y_test = test_df[self.target_column].values.astype(np.float32)\n",
    "        \n",
    "        # Create time series generators for training and testing\n",
    "        train_data_gen = TimeseriesGenerator(X_train, y_train,\n",
    "                                             length=self.sequence_length, batch_size=self.batch_size)\n",
    "        test_data_gen = TimeseriesGenerator(X_test, y_test,\n",
    "                                            length=self.sequence_length, batch_size=self.batch_size)\n",
    "    \n",
    "\n",
    "        return train_data_gen, test_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TabularLSTMDataPreprocessor\n",
    "data_preprocessor = TabularLSTMDataPreprocessor(df, target_column='nat_demand', time_column='datetime',\n",
    "                                                categorical_columns=['holiday', 'school', 'Holiday_ID'],\n",
    "                                                scaler='standard', sequence_length=24, batch_size=64)\n",
    "\n",
    "# Preprocess the data and obtain data generators\n",
    "train_data_gen, test_data_gen = data_preprocessor.preprocess()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************************************** LSTM MODEL ****************************************\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define custom RMSE loss function\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "class TabularLSTMModel:\n",
    "    def __init__(self, input_shape, lstm_units=[64, 32], output_units=1):\n",
    "        self.input_shape = input_shape\n",
    "        self.lstm_units = lstm_units\n",
    "        self.output_units = output_units\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        for units in self.lstm_units:\n",
    "            model.add(LSTM(units, return_sequences=True, input_shape=self.input_shape, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.output_units))\n",
    "        return model\n",
    "\n",
    "    def compile(self, learning_rate=0.001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "\n",
    "    def fit(self, train_data_gen, epochs=10):\n",
    "        self.model.fit(train_data_gen, epochs=epochs)\n",
    "\n",
    "    def evaluate(self, test_data_gen):\n",
    "        return self.model.evaluate(test_data_gen)\n",
    "    \n",
    "    def predict(self, data_gen):\n",
    "        return self.model.predict(data_gen)\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m35,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m3,136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m193\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,385</span> (204.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,385\u001b[0m (204.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,385</span> (204.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,385\u001b[0m (204.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1880s\u001b[0m 3s/step - loss: 716.0698\n",
      "Epoch 2/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2089s\u001b[0m 4s/step - loss: 191.2664\n",
      "Epoch 3/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3449s\u001b[0m 6s/step - loss: 161.6668\n",
      "Epoch 4/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27342s\u001b[0m 50s/step - loss: 123.7503\n",
      "Epoch 5/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 2s/step - loss: 111.9854\n",
      "Epoch 6/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m839s\u001b[0m 2s/step - loss: 111.0639\n",
      "Epoch 7/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1197s\u001b[0m 2s/step - loss: 114.4917\n",
      "Epoch 8/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m835s\u001b[0m 2s/step - loss: 107.9323\n",
      "Epoch 9/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6313s\u001b[0m 12s/step - loss: 102.4032\n",
      "Epoch 10/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1806s\u001b[0m 3s/step - loss: 108.5418\n",
      "Epoch 11/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1768s\u001b[0m 3s/step - loss: 99.5069\n",
      "Epoch 12/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1741s\u001b[0m 3s/step - loss: 103.1108\n",
      "Epoch 13/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1771s\u001b[0m 3s/step - loss: 95.0265\n",
      "Epoch 14/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1740s\u001b[0m 3s/step - loss: 92.3841\n",
      "Epoch 15/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30280s\u001b[0m 56s/step - loss: 87.5404\n",
      "Epoch 16/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1721s\u001b[0m 3s/step - loss: 87.0632\n",
      "Epoch 17/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16411s\u001b[0m 30s/step - loss: 85.1494\n",
      "Epoch 18/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16186s\u001b[0m 30s/step - loss: 82.1946\n",
      "Epoch 19/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m823s\u001b[0m 2s/step - loss: 75.8829\n",
      "Epoch 20/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1213s\u001b[0m 2s/step - loss: 72.8992\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 245ms/step - loss: 80.4242\n",
      "Test Loss (RMSE): 89.66911315917969\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the TabularLSTMModel with two LSTM layers\n",
    "input_shape = (24, 75)\n",
    "lstm_units = [64, 32, 16, 8]  # Define the units for each LSTM layer\n",
    "lstm_model = TabularLSTMModel(input_shape, lstm_units)\n",
    "num_epochs = 20\n",
    "lstm_model.summary()\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(learning_rate=0.001)\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(train_data_gen, epochs=num_epochs)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss = lstm_model.evaluate(test_data_gen)\n",
    "print(f'Test Loss (RMSE): {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************************** RESULT *********************************\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, mean_poisson_deviance, mean_gamma_deviance, mean_tweedie_deviance, mean_absolute_percentage_error\n",
    "\n",
    "class Result:\n",
    "    def __init__(self, model, test_data_gen):\n",
    "        self.model = model\n",
    "        self.test_data_gen = test_data_gen\n",
    "        self.y_true = None\n",
    "        self.y_pred = None\n",
    "\n",
    "    def evaluate(self):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(len(self.test_data_gen)):\n",
    "            x_batch, y_batch = self.test_data_gen[i]\n",
    "            y_true_batch = y_batch\n",
    "            y_pred_batch = self.model.predict(x_batch)\n",
    "\n",
    "            # Append values to the lists within the loop\n",
    "            y_true.extend(y_true_batch)\n",
    "            y_pred.extend(y_pred_batch)\n",
    "\n",
    "        self.y_true = np.array(y_true).flatten()\n",
    "        self.y_pred = np.array(y_pred).flatten()\n",
    "\n",
    "        mae = mean_absolute_error(self.y_true, self.y_pred)\n",
    "        mse = mean_squared_error(self.y_true, self.y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "        mape = mean_absolute_percentage_error(self.y_true, self.y_pred)\n",
    "        \n",
    "        r2 = r2_score(self.y_true, self.y_pred)\n",
    "        explained_variance = explained_variance_score(self.y_true, self.y_pred)\n",
    "        max_err = max_error(self.y_true, self.y_pred)\n",
    "        poisson_deviance = mean_poisson_deviance(self.y_true, self.y_pred)\n",
    "        gamma_deviance = mean_gamma_deviance(self.y_true, self.y_pred)\n",
    "        tweedie_deviance = mean_tweedie_deviance(self.y_true, self.y_pred)\n",
    "\n",
    "        return {\n",
    "            \"MAE\": mae,\n",
    "            \"MSE\": mse,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE\": mape,\n",
    "            \"R2\": r2,\n",
    "            \"Explained Variance\": explained_variance,\n",
    "            \"Max Error\": max_err,\n",
    "            \"Mean Poisson Deviance\": poisson_deviance,\n",
    "            \"Mean Gamma Deviance\": gamma_deviance,\n",
    "            \"Mean Tweedie Deviance\": tweedie_deviance\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics saved to lstm_evaluation.txt\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "result = Result(lstm_model, test_data_gen)\n",
    "evaluation = result.evaluate()\n",
    "clear_output()\n",
    "y_true_lstm = result.y_true\n",
    "y_pred_lstm = result.y_pred\n",
    "# Save the output to a text file\n",
    "output_filename = \"lstm_evaluation.txt\"\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    output_file.write(\"LSTM Model Evaluation Metrics --\\n\")\n",
    "    for metric, value in evaluation.items():\n",
    "        output_file.write(f\"{metric}: {value}\\n\")\n",
    "\n",
    "print(f\"Evaluation metrics saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27,072</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">624</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m27,072\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │         \u001b[38;5;34m2,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m624\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m193\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,697</span> (155.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,697\u001b[0m (155.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,697</span> (155.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,697\u001b[0m (155.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4165s\u001b[0m 8s/step - loss: 473.7155\n",
      "Epoch 2/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1040s\u001b[0m 2s/step - loss: 117.0319\n",
      "Epoch 3/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2076s\u001b[0m 4s/step - loss: 112.7898\n",
      "Epoch 4/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 4s/step - loss: 102.1562\n",
      "Epoch 5/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2117s\u001b[0m 4s/step - loss: 98.9811\n",
      "Epoch 6/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38778s\u001b[0m 71s/step - loss: 93.2469\n",
      "Epoch 7/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2141s\u001b[0m 4s/step - loss: 87.9017\n",
      "Epoch 8/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1158s\u001b[0m 2s/step - loss: 87.2100\n",
      "Epoch 9/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1064s\u001b[0m 2s/step - loss: 90.0497\n",
      "Epoch 10/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1050s\u001b[0m 2s/step - loss: 82.4632\n",
      "Epoch 11/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 2s/step - loss: 84.6143\n",
      "Epoch 12/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 2s/step - loss: 78.6678\n",
      "Epoch 13/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1056s\u001b[0m 2s/step - loss: 71.7750\n",
      "Epoch 14/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1061s\u001b[0m 2s/step - loss: 73.7080\n",
      "Epoch 15/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1788s\u001b[0m 3s/step - loss: 62.6553\n",
      "Epoch 16/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5270s\u001b[0m 10s/step - loss: 63.0846\n",
      "Epoch 17/20\n",
      "\u001b[1m545/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2367s\u001b[0m 4s/step - loss: 58.6908\n",
      "Epoch 18/20\n",
      "\u001b[1m494/545\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m28:35\u001b[0m 34s/step - loss: 55.7568"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Define custom RMSE loss function\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "class TabularGRUModel:\n",
    "    def __init__(self, input_shape, gru_units=[64, 32], output_units=1):\n",
    "        self.input_shape = input_shape\n",
    "        self.gru_units = gru_units\n",
    "        self.output_units = output_units\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        for units in self.gru_units:\n",
    "            model.add(GRU(units, return_sequences=True, input_shape=self.input_shape, activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(self.output_units))\n",
    "        return model\n",
    "\n",
    "    def compile(self, learning_rate=0.001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(loss=root_mean_squared_error, optimizer=optimizer)\n",
    "\n",
    "    def fit(self, train_data_gen, epochs=10):\n",
    "        self.model.fit(train_data_gen, epochs=epochs)\n",
    "\n",
    "    def evaluate(self, test_data_gen):\n",
    "        return self.model.evaluate(test_data_gen)\n",
    "    \n",
    "    def predict(self, data_gen):\n",
    "        return self.model.predict(data_gen)\n",
    "    \n",
    "    def summary(self):\n",
    "        return self.model.summary()\n",
    "    \n",
    "\n",
    "    \n",
    "# Instantiate the TabularGRUModel with two GRU layers\n",
    "input_shape = (24, 75)\n",
    "gru_units = [64, 32, 16, 8]  # Define the units for each GRU layer\n",
    "num_epochs = 20\n",
    "gru_model = TabularGRUModel(input_shape, gru_units)\n",
    "gru_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "gru_model.compile(learning_rate=0.001)\n",
    "\n",
    "# Train the model using the train_data_gen\n",
    "gru_model.fit(train_data_gen, epochs=num_epochs)\n",
    "\n",
    "# Evaluate the model on the test data using the test_data_gen\n",
    "loss = gru_model.evaluate(test_data_gen)\n",
    "print(f'Test Loss (RMSE): {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "result_gru = Result(gru_model, test_data_gen)\n",
    "evaluation = result_gru.evaluate()\n",
    "clear_output()\n",
    "y_true_gru = result_gru.y_true\n",
    "y_pred_gru = result_gru.y_pred\n",
    "# Save the output to a text file\n",
    "output_filename = \"gru_evaluation.txt\"\n",
    "with open(output_filename, \"w\") as output_file:\n",
    "    output_file.write(\"GRU Model Evaluation Metrics --\\n\")\n",
    "    for metric, value in evaluation.items():\n",
    "        output_file.write(f\"{metric}: {value}\\n\")\n",
    "\n",
    "print(f\"Evaluation metrics saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'y_true': y_true_lstm, 'y_pred': y_pred_lstm}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the filename for the CSV file\n",
    "csv_filename = 'lstm_predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'y_true': y_true_gru, 'y_pred': y_pred_gru}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Specify the filename for the CSV file\n",
    "csv_filename = 'gru_predictions.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
